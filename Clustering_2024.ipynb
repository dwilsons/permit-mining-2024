{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import seaborn as sb\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import HDBSCAN\n",
    "from kmodes.kmodes import KModes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data (loads binary dataframe, for using new version with both binary and age data just take only the binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('SDGEproperty_upgrade_data.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first section prepares the binary data for clustering. This includes: pulling only desired columns (including selecting properties based on certain conditions) and then selecting only properties with >1 upgrade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For pulling specific data\n",
    "\n",
    "columns = list(df)[11:39]\n",
    "column_set = [\n",
    "    'Solar PV',\n",
    "    'Battery storage',\n",
    "    'Electric Vehicle Charger',\n",
    "    'Electrical Panel Upgrade',\n",
    "    'Water Heater',\n",
    "    'Cool Roof',\n",
    "    'Kitchen Remodel',\n",
    "    'Bathroom Remodel',\n",
    "    'AC',\n",
    "    'Reroof',\n",
    "    'Spa/Pool'\n",
    "    ]\n",
    "\n",
    "# df_u = df[df['Cool Roof'] == 1]\n",
    "# df_u = df_u[df_u['Electrical Panel Upgrade'] == 0]\n",
    "# df_u = df[(df['AC'] == 0) & (df['Cool Roof'] == 1)]\n",
    "df_u = df[columns]\n",
    "# df_u = df_u[df_u[column_set[8]] == 1]\n",
    "# data = df_u.to_numpy(dtype='int')\n",
    "# dsc = data[~np.all(data == 0, axis=1)]\n",
    "df_u.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(column_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brief intermission to check conditional probability for an upgrade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes dataframe, an upgrade to check for (x) and the upgrade set (Y)\n",
    "# to give result of P(x|y_i) for y_i in Y\n",
    "def cond_probs(df, upgrade, u_set):\n",
    "    total = len(df)\n",
    "    p_A = float(len(df[df[upgrade] == 1])/total)\n",
    "    print(\"Normal probability: \" + str(p_A))\n",
    "    for u in u_set:\n",
    "        p_B = float(len(df[df[u] == 1])/total)\n",
    "        p_U = float(len(df[(df[upgrade] == 1) & (df[u] == 1)])/total)\n",
    "        p_C = float(p_U/p_B)\n",
    "        print(\"Conditional probability given \" + u + \": \" + str(p_C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_probs(df_u, 'Cool Roof', column_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to preparing data (checking for >1 upgrade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_mult(bool_list):\n",
    "    mult = 0\n",
    "    for val in bool_list:\n",
    "        if val == 1:\n",
    "            mult += 1\n",
    "    if mult >= 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "bools = []\n",
    "for row in df_u.itertuples():\n",
    "    bool_list = list(row[1:])\n",
    "    if check_mult(bool_list):\n",
    "        bools.append(bool_list)\n",
    "    if i % 50000 == 0:\n",
    "        print(i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, property data is set as binary numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(bools)\n",
    "train, test = train_test_split(data, test_size = 0.2)\n",
    "sub, sub2 = train_test_split(test, test_size = 0.5)\n",
    "print(len(train))\n",
    "print(len(test))\n",
    "print(len(sub))\n",
    "print(data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks percentage of full data that is being clustered (based on conditions)\n",
    "print((float(len(data)/len(df_u))) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation, Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = np.corrcoef(data.T)\n",
    "heatmap = sb.heatmap(correlation, xticklabels=column_set, annot=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = cosine_similarity(data.T)\n",
    "heatmap = sb.heatmap(similarities, yticklabels=columns, xticklabels=columns, vmax=0.5, annot=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section is for K-modes clustering. This essentially works the same as k-means with the difference being how cost is calculated. Instead of calculating cost as euclidean distance from cluster centroids to data points, cost is calculated as the number of differences in values between centroids and data. As a result, k-modes is more effective for binary data (like the binary upgrade data). The first section takes a smaller set of the overall data set to test with many values of k so an educated decision can be made for k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates cost for different k\n",
    "\n",
    "cost = []\n",
    "centroids = []\n",
    "labels = []\n",
    "for i in range(2, 16):\n",
    "    print(i)\n",
    "    km_h = KModes(n_clusters=i, init='Huang', n_init = 1)\n",
    "    km_h.fit_predict(sub)\n",
    "    cost.append(km_h.cost_)\n",
    "    centroids.append(km_h.cluster_centroids_)\n",
    "    labels.append(km_h.labels_)\n",
    "print(len(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost vs. k (use elbow method as a rough way to decide on good k)\n",
    "\n",
    "x = np.arange(2, 16, 1)\n",
    "plt.plot(x, cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, clustering is conducted with the entire data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering, prints final cluster centroids when finished\n",
    "# n_init sets how many runs to do, feel free to change\n",
    "\n",
    "km_huang = KModes(n_clusters=10, init = \"Huang\", n_init = 5, verbose=1)\n",
    "km_huang.fit_predict(data)\n",
    "print(len(km_huang.labels_))\n",
    "print(km_huang.cluster_centroids_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints number of properties in each cluster\n",
    "\n",
    "totals_huang = {}\n",
    "for i in range(0, len(km_huang.labels_)):\n",
    "    label_huang = km_huang.labels_[i]\n",
    "    if label_huang in totals_huang.keys():\n",
    "        totals_huang[label_huang] += 1\n",
    "    else:\n",
    "        totals_huang[label_huang] = 1\n",
    "\n",
    "for i in range(0, len(totals_huang.keys())):\n",
    "    print(i, totals_huang[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bernoulli Mixture Method (BMM) section. BMM, in the simplest terms, clusters the data into clusters which are built from multiple bernoulli distributions. The result is you have k clusters, each with their own cluster likelihood (how likely a property is to fall into that cluster), and in each cluster the likelihood of a certain upgrade being present (results of the bernoulli distributions, the BERNOULLI MIXTURE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements specific to BMM since there are a few\n",
    "from bayespy.nodes import Categorical, Dirichlet\n",
    "from bayespy.nodes import Beta\n",
    "from bayespy.nodes import Mixture, Bernoulli\n",
    "from bayespy.inference import VB\n",
    "import bayespy.plot as bpplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for BMM\n",
    "\n",
    "bern = data.copy()\n",
    "N = len(bern)\n",
    "D = 11\n",
    "K = 1 # pick multiple and check results, not a perfect science\n",
    "\n",
    "R = Dirichlet(K*[1e-5], name='R')               # sets initial properties for each cluster\n",
    "Z = Categorical(R, plates=(N,1), name='Z')      \n",
    "P = Beta([0.5, 0.5], plates=(D,K), name='P')    # sets initial properties for each upgrade in each cluster\n",
    "X = Mixture(Z, Bernoulli, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "Q = VB(Z, R, X, P)\n",
    "P.initialize_from_random()\n",
    "X.observe(bern)\n",
    "Q.update(repeat=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last section makes hinton plots for the BMM. Alas, the libary's function does not allow for labels. To read the plots, use the boxes-a bigger box means more likely. Clusters go left to right, upgrades go top to bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster P\n",
    "bpplt.hinton(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upgrade P per cluster\n",
    "bpplt.hinton(P)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EE443FinalProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
